#!/usr/bin/env python3

"""
This script parses the reports generated by TrimGalore, Kraken2, and BWA and generates a single coherent report
"""

### ---------------------------------------- ###

def parseTrimGaloreReport(report_name):
    
    report = open(report_name).read().split('\n')
    
    raw_reads = [int(line.split(' ')[-1].replace(',', '')) for line in report if 'Total reads processed:' in line][0]
    reads_with_adapters = [int(line.split(' ')[-2].replace(',', '')) for line in report if 'Reads with adapters:' in line][0]
    trimmed_reads = [int(line.split(' ')[-2].replace(',', '')) for line in report if 'Reads written (passing filters):' in line][0]
    
    return raw_reads, reads_with_adapters, trimmed_reads

### ---------------------------------------- ###

def parseKraken2Report(report_name):
    
    report = open(report_name).read().split('\n')

    try:
        
        kraken_immitis_reads = [int(line.split('\t')[1].replace(',', '')) for line in report if 'Coccidioides immitis' in line][0]
        kraken_immitis_unique_minimizers = [int(line.split('\t')[4].replace(',', '')) for line in report if 'Coccidioides immitis' in line][0]
    
    except:
        
        kraken_immitis_reads, kraken_immitis_unique_minimizers = 0, 0
    
    try:
        
        kraken_posadasii_reads = [int(line.split('\t')[1].replace(',', '')) for line in report if 'Coccidioides posadasii' in line][0]
        kraken_posadasii_unique_minimizers = [int(line.split('\t')[4].replace(',', '')) for line in report if 'Coccidioides posadasii' in line][0]
    
    except:
        
        kraken_posadasii_reads, kraken_posadasii_unique_minimizers = 0, 0
    
    return kraken_immitis_reads, kraken_immitis_unique_minimizers, kraken_posadasii_reads, kraken_posadasii_unique_minimizers

### ---------------------------------------- ###

def parseMappingReport(report_name):
    
    report = open(report_name).read().split('\n')
    
    mapping_percentage = [float(line.split(' ')[-1][1:-1].split('%')[0]) for line in report if 'properly paired' in line][0]
    
    return mapping_percentage

### ---------------------------------------- ###

def parseDuplicationReport(report_name):
    
    _, header, dup_data = [block for block in open(report_name).read().split('\n\n') if '## METRICS CLASS\tpicard.sam.DuplicationMetrics' in block][0].split('\n')
    
    percent_duplication = float(dup_data.split('\t')[header.split('\t').index('PERCENT_DUPLICATION')])
    
    return percent_duplication

### ---------------------------------------- ###

def parseCoverageReport(report_name):
    
    _, metrics_header, metrics = [block for block in open(report_name).read().split('\n\n') if '## METRICS' in block][0].split('\n')
    metrics_header, metrics = metrics_header.split('\t'), metrics.split('\t')
    desired_fields = ['MEAN_COVERAGE', 'MEDIAN_COVERAGE', 'SD_COVERAGE', 'PCT_5X', 'PCT_10X', 'PCT_25X', 'PCT_50X', 'PCT_100X']
    mean_coverage, median_coverage, sd_coverage, cov_5, cov_10, cov_25, cov_50, cov_100 = [metrics[metrics_header.index(h)] if h in metrics_header else '' for h in desired_fields]
    
    return mean_coverage, median_coverage, sd_coverage, cov_5, cov_10, cov_25, cov_50, cov_100

### ------------------MAIN------------------ ###

from datetime import datetime
from sys import argv

### PARSE DATA ----------------------------- ###

# Import reads/sample list file name
reads_list_file = argv[argv.index("--reads_list_file") + 1]

# Import reads/sample list
reads_list = open(reads_list_file).read().split('\n')
reads_list_header, reads_list = reads_list[0].split('\t'), reads_list[1:]

# Init summary report
summary_header = ["Sample",
                  "Batch",
                  "Raw_Reads",
                  "Raw_Reads_With_Adapters",
                  "Trimmed_Raw_Reads",
                  "Kraken2_Raw_Reads_C.immitis",
                  "Kraken2_Raw_Reads_C.posadasii",
                  "Kraken2_UniqueMinimizers_C.immitis",
                  "Kraken2_UniqueMinimizers_C.posadasii",
                  "Mapping_Percentage_C.immitis",
                  "Mapping_Percentage_C.posadasii",
                  "Duplication_Percentage_C.immitis",
                  "Duplication_Percentage_C.posadasii",
                  "Coverage_Mean_C.immitis",
                  "Coverage_Mean_C.posadasii",
                  "Coverage_Median_C.immitis",
                  "Coverage_Median_C.posadasii",
                  "Coverage_SD_C.immitis",
                  "Coverage_SD_C.posadasii",
                  "Coverage_5+_Percentage_C.immitis",
                  "Coverage_5+_Percentage_C.posadasii",
                  "Coverage_10+_Percentage_C.immitis",
                  "Coverage_10+_Percentage_C.posadasii",
                  "Coverage_25+_Percentage_C.immitis",
                  "Coverage_25+_Percentage_C.posadasii",
                  "Coverage_50+_Percentage_C.immitis",
                  "Coverage_50+_Percentage_C.posadasii",
                  "Coverage_100+_Percentage_C.immitis",
                  "Coverage_100+_Percentage_C.posadasii"]

summary = {h : [] for h in summary_header}

# Parse data for each sample specified in reads_list
for index, row in enumerate(reads_list):

    if not len(row):

        continue
    
    # Extract basic info
    sample, batch, fastq_1 = [row.split('\t')[reads_list_header.index(element)] for element in ['sample', 'batch', 'fastq_1']]
    summary['Sample'].append(sample)
    summary['Batch'].append(batch)
    
    # Parse R1 TrimGalore report
    raw_reads, reads_with_adapters, trimmed_reads = parseTrimGaloreReport(f'{fastq_1.split("/")[-1]}_trimming_report.txt')
    summary['Raw_Reads'].append(raw_reads)
    summary['Raw_Reads_With_Adapters'].append(reads_with_adapters)
    summary['Trimmed_Raw_Reads'].append(trimmed_reads)
    
    # Parse info from Kraken2 report
    immitis_raw_reads, immitis_minimizers, posadasii_reads, posadasii_minimizers = parseKraken2Report(f'{sample}_kraken.report')
    summary['Kraken2_Raw_Reads_C.immitis'].append(immitis_raw_reads)
    summary['Kraken2_UniqueMinimizers_C.immitis'].append(immitis_minimizers)
    summary['Kraken2_Raw_Reads_C.posadasii'].append(posadasii_reads)
    summary['Kraken2_UniqueMinimizers_C.posadasii'].append(posadasii_minimizers)
    
    # Parse mapping info
    try:
        
        immitis_percentage_mapped_reads = parseMappingReport(f'{sample}_mapping_immitis.log')
    
    except:
        
        immitis_percentage_mapped_reads = 'NA'
    
    try:
        
        posadasii_percentage_mapped_reads = parseMappingReport(f'{sample}_mapping_posadasii.log')
    
    except:
        
        posadasii_percentage_mapped_reads = 'NA'
    
    summary['Mapping_Percentage_C.immitis'].append(immitis_percentage_mapped_reads)
    summary['Mapping_Percentage_C.posadasii'].append(posadasii_percentage_mapped_reads)
    
    # Parse duplication info
    try:
        
        immitis_duplication_percentage = parseDuplicationReport(f'{sample}_marked_dup_metrics_immitis.txt')
    
    except:
        
        immitis_duplication_percentage = 'NA'
    
    try:
        
        posadasii_duplication_percentage = parseDuplicationReport(f'{sample}_marked_dup_metrics_immitis.txt')
    
    except:
        
        posadasii_duplication_percentage = 'NA'
    
    summary['Duplication_Percentage_C.immitis'].append(immitis_duplication_percentage)
    summary['Duplication_Percentage_C.posadasii'].append(posadasii_duplication_percentage)
    
    # Parse coverage info for C. immitis
    try:
        
        mean, median, sd, cov_5, cov_10, cov_25, cov_50, cov_100 = parseCoverageReport(f'{sample}_coverage_stats_immitis.txt')
        
    except:
        
        mean, median, sd, cov_5, cov_10, cov_25, cov_50, cov_100 = 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA'
    
    summary['Coverage_Mean_C.immitis'].append(mean)
    summary['Coverage_Median_C.immitis'].append(median)
    summary['Coverage_SD_C.immitis'].append(sd)
    summary['Coverage_5+_Percentage_C.immitis'].append(cov_5)
    summary['Coverage_10+_Percentage_C.immitis'].append(cov_10)
    summary['Coverage_25+_Percentage_C.immitis'].append(cov_25)
    summary['Coverage_50+_Percentage_C.immitis'].append(cov_50)
    summary['Coverage_100+_Percentage_C.immitis'].append(cov_100)
    
    # Parse coverage info for C. posadasii
    try:
        
        mean, median, sd, cov_5, cov_10, cov_25, cov_50, cov_100 = parseCoverageReport(f'{sample}_coverage_stats_posadasii.txt')
        
    except:
        
        mean, median, sd, cov_5, cov_10, cov_25, cov_50, cov_100 = 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA'
    
    summary['Coverage_Mean_C.posadasii'].append(mean)
    summary['Coverage_Median_C.posadasii'].append(median)
    summary['Coverage_SD_C.posadasii'].append(sd)
    summary['Coverage_5+_Percentage_C.immitis'].append(cov_5)
    summary['Coverage_10+_Percentage_C.immitis'].append(cov_10)
    summary['Coverage_25+_Percentage_C.immitis'].append(cov_25)
    summary['Coverage_50+_Percentage_C.immitis'].append(cov_50)
    summary['Coverage_100+_Percentage_C.posadasii'].append(cov_100)

### EXPORT DATA ---------------------------- ###

# Formatting text
summary_text = '\n'.join(['\t'.join(summary_header)] +
                         ['\t'.join([str(summary[h][i]) for h in summary_header]) for i in range(len(summary['Sample']))])

# Saving to tsv

out_name_prefix = reads_list_file.split('/')[-1].replace('.tsv', '').replace('.txt', '')
time_stamp = str(datetime.now()).replace(" ", "_").replace(":", "-")

with open(f'{out_name_prefix}_{time_stamp}.tsv', 'w') as summary_out:
    
    summary_out.write(summary_text)
